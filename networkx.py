# -*- coding: utf-8 -*-
"""Networkx.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GjJa9PUPezJSsfxYstxn7LJnvStYjTd2
"""

aG = nx.MultiGraph()

source_nodes = ['P', 'B', 'C', 'D','D']
dest_nodes = ['P', 'P', 'R', 'S', 'S']

for u,v in zip(source_nodes, dest_nodes):
    G.add_edge(u, v)


for i in G.nodes:
    print(i, G.edges(i))
nx.draw(G,with_labels=1)

import networkx as nx
G=nx.MultiGraph()
source_nodes = [1, 2, 1, 2,'D']
dest_nodes = ['P', 'P', 'R', 'S', 'S']
print(G.nodes())
for u,v in zip(source_nodes, dest_nodes):
    G.add_edge(u, v)
for i in G.nodes:
    print(i, G.edges(i))
nx.draw(G,with_labels=1)
'''G.add_nodes_from([2,10,3,5,4,'cold'])
G.add_nodes_from(["cold"])
G.add_nodes_from("cold")
G.nodes()
G.remove_node(2)
G.nodes()'''

import networkx as nx
G=nx.complete_graph(50)
nx.draw_circular(G)

import networkx
G=networkx.Graph()
G.add_node(1)
G.add_node(2)
G.nodes()
G.add_edge(1,2)
G.add_edge(2,3)
G.add_edge(3,4)
G.edges()
G.add_edge(1,5)
G.nodes()
G.edges()
G=networkx.Graph()
import networkx as nx
F=nx.Graph()
G.add_node(1)
G.add_node(2)
G.add_node(3)
G.add_node(4)
G.nodes()
G.add_edge(1,2)
G.add_edge(2,3)
G.add_edge(3,4)
G.edges()
import matplotlib.pyplot as plt
nx.draw(G)
nx.draw(G,with_labels=1)

import networkx as nx
M=nx.Graph()
M.add_node(1)
M.add_node(2)
M.add_node(3)
M.add_node(4)
M.nodes()
M.add_edge(1,2)
M.add_edge(3,4)
M.add_edge(1,3)
M.add_edge(2,4)
M.edges()
nx.draw(M)
nx.draw(M,with_labels=1)

import networkx as nx
G=nx.complete_graph(25)
nx.draw_random(G)

import networkx as nx
G=nx.complete_graph(105)
nx.draw_circular(G)
nx.draw(G,with_labels=2,node_color='r')

import networkx as nx
K=nx.complete_graph(5)
nx.draw(K,node_color='g',with_labels=3)

L=nx.complete_graph(50)
nx.draw(L)
L.order()
L.size()

l=[2,2,3]
nx.is_graphical(l)

import networkx as nx
N=nx.Graph()
N.add_node(1)
N.add_node(2)
N.add_node(3)
N.add_node(4)
N.nodes()
N.add_edge(1,2)
N.add_edge(2,3)
N.add_edge(3,4)
N.add_edge(1,4)
N.edges()
nx.draw(N)
nx.draw(N,node_color='y',with_labels=1)
print("N.degree=", N.degree)
print("hops:4")

import networkx as nx
g=nx.Graph()
g.add_edges_from([(1,2),(1,3),(2,3)])
'''g.add_edge(1,2)
g.add_edge(1,3)
g.add_edge(1,4)
g.add_edge(1,5)'''
import matplotlib.pyplot as plt
nx.draw(g,with_labels=1,node_color='r')

import networkx as nx
g=nx.Graph()
g.add_node(1,pos=(1,2))
g.add_node(2,pos=(2,3))
g.add_node(3,pos=(2,1))
g.add_node(4,pos=(3,3))
g.add_node(5,pos=(3,1))
g.add_node(6,pos=(4,2))
g.add_edges_from([(1,2),(1,3),(2,4),(2,5),(3,4),(3,5),(4,6),(5,6)])
pos=nx.get_node_attributes(g,'pos')
nx.draw(g,pos,with_labels=1,node_color='g')

import networkx as nx
g=nx.Graph()
g.add_node(1,pos=(0,6))
g.add_node(2,pos=(5,0))
g.add_node(3,pos=(9,4))
g.add_node(4,pos=(8,10))
g.add_node(5,pos=(15,0))
g.add_node(6,pos=(16,6))
g.add_node(7,pos=(13,11))
g.add_node(8,pos=(7,15))
g.add_edge(1,2,weight=0)
g.add_edge(2,4,weight='2km')
g.add_edge(3,4,weight='3km')
g.add_edge(5,6,weight='4km')
g.add_edge(6,4,weight='5km')
g.add_edge(4,8,weight='6km')
g.add_edge(3,6,weight='7km')
g.add_edge(1,4,weight='2km')
g.add_edge(4,7,weight='3km')
g.add_edge(4,5,weight='4km')
g.add_edge(7,8,weight='5km')
g.add_edge(2,5,weight='1km')
pos=nx.get_node_attributes(g,'pos')
labels=nx.get_edge_attributes(g,'weight')
nx.draw_networkx_edge_labels(g,pos,edge_labels=labels)
nx.draw(g,pos,with_labels=1)
print('cluster: ',nx.clustering(g,nodes=4,weight=6));
print('eccentricity=',nx.eccentricity(g))
print('radius=',nx.radius(g))
s = int(input("Source: "))
d = int(input("Destination: "))
print('shortest_path=',nx.shortest_path(g,source=s,target=d))
print('shortest_path_length=', nx.shortest_path_length(g,source=s,target=d))
print("average_shortest_path_length: ",nx.average_shortest_path_length(g))
nx.degree(g)

import networkx as nx
import matplotlib.pyplot as plt
P = nx.erdos_renyi_graph(50, 0.5)
nx.draw(P,with_labels=1,node_color = 'y')

s = int(input("Source: "))
d = int(input("Destination: "))
print(nx.shortest_path(P,source=s,target=d))
print(nx.shortest_path_length(P,source=s,target=d))

l = nx.all_shortest_paths(P, source=s,target=d)
print(list(l))

P.degree()

v = int(input("Enter the node: "))
P.degree[v]

#the higher the degree is the more central it is
nx.degree_centrality(P)

nx.degree(G,4)

#average path length
import networkx as nx
N=nx.Graph()
N.add_node(1)
N.add_node(2)
N.add_node(3)
N.add_node(4)
N.nodes()
N.add_edge(1,2)
N.add_edge(2,3)
N.add_edge(3,4)
N.add_edge(1,4)
N.edges()
nx.draw(N,node_color='y',with_labels=1)
print(nx.average_shortest_path_length)

import networkx as nx
G=nx.path_graph(50)

print(nx.average_shortest_path_length(G))

import networkx as nx
import matplotlib.pyplot as plt
n=int(input("enter number of nodes:"))      #pos=nx.spring_layout(G) or nx.kamada_kawai_layout(G) or nx.circular_layout(G) or nx.spectral_layout(G)
p=eval(input("enter probability:"))                                # or nx.shell_layout(G) or nx.fruchterman_reingold_layout(G)
G=nx.gnp_random_graph(n,p)
cir=nx.circular_layout(G)
f=nx.fruchterman_reingold_layout(G)
l=eval(input("enter type of layout:"))
pos=l
i=int(input("enter the size of the graph:"))
plt.figure(figsize=(i,i))
c=input("enter the color of nodes:")
nx.draw(G,pos,node_size=i*i,font_size=i,with_labels=1,node_color=c)                               #color=c,g,r,y,b

n = int(input("Enter the node: "))
print('No.of triangles with n as one of the vertices: ',nx.triangles(G,n))
print('Clustering Coefficient of node n is',nx.clustering(G,n))   #clustering coefficient of node n = [2T(n)]/[deg(n)(deg(n)-1)]
print('The Average Clustering coefficient of the Graph is',nx.average_clustering(G))

import networkx as nx
#import matplotlib.pyplot as plt
g=nx.Graph([(1,0),(1,0),(2,1),(3,0)])
g.add_node('A',role='manager')
g.add_edge('A','B',relation ='friend')
#g.nodes['A']['role'] = 'team member'
print(g.nodes['A'], g.edges[('A','B')])
dict(g.edges())
#g.add_edges_from([(1,0),(1,0),(2,1),(3,0)])
#nx.draw_networkx(g)
nx.draw(g,with_labels=1)
print(g.edges())
print(g.nodes())
g.nodes()
dict(g.edges())
dict(g.degree())

import networkx as nx
import matplotlib.pyplot as plt
G=nx.gnp_random_graph(20,.3)
pos=nx.fruchterman_reingold_layout(G)
print(nx.clustering(G,15))
print(nx.transitivity(G))
#G.transitivity()  error
plt.figure(figsize=(10,10))
nx.draw(G,pos,node_size=10*10,font_size=10,with_labels=1,node_color='y')

"""#                          ** DEGREE CALCULATIONS**

"""

import networkx as nx
g=nx.Graph()
#n=int(input("enter number of nodes: "))
n=20
radius=1000
for i in range(1,n):   #n-1 will be taken in range
  g.add_edge(i,i+1)
  if i>18:
   continue
  g.add_edge(i,i+2)
  if i>10:
    continue
  g.add_edge(i,i*2)
  if i>6:
    continue
  g.add_edge(i,i*3)
  if i==n and radius==1000:
    break
dictionary={}
for i in range(1,n+1):
  my_dict={i:g.degree(i)}
  dictionary.update(my_dict)
  if 1<=i<n:
   continue
  print(dictionary.values())
  max_key = max(dictionary, key=dictionary.get)
  key=dictionary. get(max_key)
  print(f"Node with highest degree={max_key}:{key}")
print(nx.clustering(G,5))
print("average path length:",nx.average_shortest_path_length(g))
nx.draw(g,node_color='g',with_labels=1)
nx.degree(g)

import networkx as nx
import matplotlib.pyplot as plt
n=int(input("enter number of nodes:"))      #pos=nx.spring_layout(G) or nx.kamada_kawai_layout(G) or nx.circular_layout(G) or nx.spectral_layout(G)
p=eval(input("enter probability:"))                                # or nx.shell_layout(G) or nx.fruchterman_reingold_layout(G)
G=nx.gnp_random_graph(n,p)
#cir=nx.circular_layout(G)
#f=nx.fruchterman_reingold_layout(G)
l=eval(input("enter type of layout:"))
pos=l
print(G.degree())
dictionary=dict(G.degree())
max_key = max(dictionary, key=dictionary.get)
key=dictionary. get(max_key)
print(f"Node with highest degree={max_key}:{key}")
i=int(input("enter the size of the graph:"))
plt.figure(figsize=(i,i))
c=input("enter the color of nodes:")
nx.draw(G,pos,node_size=i*i,font_size=i,with_labels=1,node_color=c)                               #color=c,g,r,y,b

import networkx as nx
import matplotlib.pyplot as plt
import operator
G=nx.gnp_random_graph(20,.3)
pos=nx.fruchterman_reingold_layout(G)
D=dict(G.degree())
print(D)
SD=sorted(D.items(),key=operator.itemgetter(1),reverse=True)
my_dict=dict(SD)
print(my_dict)
print(SD)
L1=list(my_dict.keys())
print(L1)
n=int(input("enter number of degrees:"))
print("Nodes with highest degrees: ",end="")
for i in L1[0:n]:
  degree=(my_dict.get(i))
  print(f"({i}:{degree}) ",end="")
#plt.axes([0,1,2,4])
nx.draw(G,pos,with_labels=1,node_color='y')

import networkx as nx
import matplotlib.pyplot as plt
from operator import itemgetter
G=nx.random_geometric_graph(50,0.3)
pos = nx.get_node_attributes(G,'pos')
dmin = 1
ncenter=0
for n in pos:
  x,y=pos[n]
  d=(x-0.5)**2+(y-0.5)**2
  if d<dmin:
    ncenter=n
    dmin=d
p=dict(nx.single_source_shortest_path_length(G,ncenter))
plt.figure(figsize=(15,15))
nx.draw_networkx_edges(G,pos,nodelist=[ncenter],alpha=0.4)
nx.draw_networkx_nodes(G,pos,nodelist=list(p.keys()),node_size=200,node_color=list(p.values()),cmap=plt.cm.Reds_r)
nx.draw_networkx_labels(G,pos, font_size=12,font_family='sans-serif')
plt.axis('on')
plt.show()

print('Degree of nodes: ',G.degree())
print('Centrality of nodes: ',nx.degree_centrality(G))
s=int(input('Enter the source: '))
d=int(input('Enter the destination: '))
print('shortest path b/w s and d: ',nx.shortest_path(G,source=s,target=d))
print('Shortest distance between Source and Destination: ',nx.shortest_path_length(G,source=s,target=d))
tn=dict(G.degree(G.nodes()))
sorted_degree=sorted(tn.items(),key=itemgetter(1),reverse=True)
print('Top 5 nodes based on degree: ')
for n in sorted_degree[:5]:
  print(n)
top_c=dict(nx.degree_centrality(G))
sort=sorted(top_c.items(),key=itemgetter(1),reverse=True)
print('Top 5 nodes by centrality: ')
for c in sort[:5]:
  print(c)

#subgraph of the triangles
def get_triangles(G, node):
    neighbors1 = set(G.neighbors(node))
    triangle_nodes = set()
    triangle_nodes.add(node)

    for nbr1, nbr2 in (neighbors1):
        if G.has_edge(nbr1, nbr2):
            triangle_nodes.add(nbr1)
            triangle_nodes.add(nbr2)
    return triangle_nodes
l=int(input('Enter the node: '))
print(get_triangles(G, l))
nx.draw(G.subgraph(get_triangles(G,l)), with_labels=True)

import networkx as nx
import matplotlib.pyplot as plt
from operator import itemgetter
G = nx.Graph()
G.add_edges_from([(0,1),(0,2),(1,3),(2,4)])
nx.draw_networkx(G)

from networkx.algorithms import bipartite
print(bipartite.is_bipartite(G))
print(bipartite.sets(G))
print(G.edges())
nx.draw_networkx(G,pos=nx.drawing.layout.bipartite_layout(G,[0,3,4]))

n=int(input('Enter the node: '))
print(nx.clustering(G,n))
print(nx.average_clustering(G))
print(nx.transitivity(G))
print(nx.shortest_path(G,0,4))
print(nx.shortest_path_length(G,0,4))
print(nx.average_shortest_path_length(G))
print(nx.diameter(G)) #max. distance between any pair of nodes
print(nx.eccentricity(G)) #each nodes distance to its furthest node
print(nx.radius(G)) #min.eccentricity in the graph
print(nx.periphery(G)) #set of nodes where eccentricity=diameter
print(nx.center(G)) #eccentricty=raidus

T=nx.bfs_tree(G,2)
nx.draw_networkx(T)

print(nx.node_connectivity(G)) #min nodes removed to disconnect a network
print(nx.minimum_node_cut(G)) #which nodes?
print(nx.edge_connectivity(G))
print(nx.minimum_edge_cut(G))

G.clear()
G=nx.karate_club_graph()
print(G.nodes[15]["club"]) #gives Mr.Hi or Officer
nx.draw_networkx(G)

G.clear()
G=nx.random_regular_graph(5,50)
nx.draw_networkx(G)

import networkx as nx
import matplotlib.pyplot as plt
G=nx.random_geometric_graph(5,1)
#G=nx.complete_graph(20)
pos = nx.get_node_attributes(G,'pos')
print(pos)
#print(pos)
for n in pos:
  x,y=pos[n]
  #print(x,y)
  if 0.1<round(x,1)<0.5:
    dx=x+1.5
    a=[dx,y]
    pos.update({n:a})
  if 0.1<round(y,1)<0.5:
    dy=y+1.5
    b=[x,dy]
    pos.update({n:b})
print("coordinates: ",pos)
print("all the paths between source and destination:")
for path in nx.all_simple_paths(G,source=1,target=4):
  print(path)
print("shoartest_path:",nx.shortest_path(G,1,4))
nx.draw(G,pos,with_labels=1,node_color='y',width=20)

"""# calculating avg path length,avg clustring coffecient
# 5x5 graph ,**adding shortest edges** ,adding long range links
 according to top 20 nodes of betweenness centrality and highest distances
"""

import networkx as nx
import matplotlib.pyplot as plt
import random
import operator
import math
G=nx.random_geometric_graph(400,.1)
pos = nx.get_node_attributes(G,'pos')
print("coordinates before development",pos)
                                               #improving coordinates
for n in pos:
  x,y=pos[n]
  if x<1:
    dx=x+random.randint(1,4999)
    dy=y+random.randint(1,4999)
    a=[dx,dy]
    pos.update({n:a})
print("coordinates after development",pos)

#finding distances between nodes
Xlist=[]
p_Xlist=[]
Ylist=[]
p_Ylist=[]
for n1 in pos:
  x,y=pos[n1]
  Xlist.append(x)
  p_Xlist.append(x)
  Ylist.append(y)
  p_Ylist.append(y)
c=[]                                            #storing calculated values of first part of distance formula in c list
for x1 in Xlist[0:len(Xlist)]:
  for x2 in p_Xlist[1:len(p_Xlist)]:
    a=math.pow((x2-x1),2)
    c.append(a)
  if len(p_Xlist)>1:        #condition is given because anynumber in xlist is calculated with the numbers which are coming after that number same expalination for all this type of conditions in whole code
    p_Xlist.pop(1)
d=[]                                                                      #storing calculated values of second part of distance formula in d list
for y1 in Ylist[0:len(Ylist)]:
  for y2 in p_Ylist[1:len(p_Ylist)]:
    b=math.pow((y2-y1),2)
    d.append(b)
  if len(p_Ylist)>1:
    p_Ylist.pop(1)
dist_value=[]
for e in range(0,len(c)):
  distance=math.sqrt(c[e]+d[e])   #distance=sqrt(x2-x1)^2+(y2-y1)^2)    #distance=math.sqrt(math.pow((x2-x1),2)+math.pow((y2-y1),2))
  dist_value.append(distance)
#print("dist_value",dist_value)
print("dist_value",len(dist_value))
k=[]
pop_k=[]                                            #storing the node numbers of pos in pop_k so to use them to pop out the values
for n2 in pos:
  k.append(n2)
  pop_k.append(n2)
node_list=[]                                     #storing node pairs such that 1st node and 2nd node in a list are taken in tuple
for u in k:
  for v in pop_k[1:len(pop_k)]:
    m=(u,v)
    node_list.append(m)
  if len(pop_k)>1:
    pop_k.pop(1)
print(len(node_list))
dist_dict={}                                         #storing the node pairs as keys and distances as values
for z in range(0,len(node_list)):
  dist_dict.update({node_list[z]:dist_value[z]})
#print("dist_dict",dist_dict)
nx.draw(G,pos,node_size=200,font_size=10,with_labels=1,node_color="g")
plt.axis('on')

for i4 in G.edges():                                     #adding color
    G[i4[0]][i4[1]]['color'] = 'y'
for n3 in dist_dict:                                     #adding shortest edges between nodes
  value=dist_dict.get(n3)
  if value>500 and G.has_edge(*n3) is True:            #unpacks
    G.remove_edge(*n3)
  if value<500 and G.has_edge(*n3) is False:
    G.add_edge(*n3)
    G[n3[0]][n3[1]]['color'] = 'r'

colors = [ G[i4[0]][i4[1]]['color'] for i4 in G.edges() ]
plt.figure(figsize=(10,10))
nx.draw(G,pos,node_size=200,edge_color=colors,font_size=10,with_labels=1,node_color="g")
plt.axis('on')

D=dict(G.degree())#D=nx.betweenness_centrality(G)                    #Finding betweeness centrality
print("betweenness_centrality:",D)
SD=sorted(D.items(),key=operator.itemgetter(1),reverse=True)    #arranging betweeness centrality values in descending order
my_dict=dict(SD)                             #converting SD into dictionary
L1=list(my_dict.keys())                      #storing the keys(nodes) of dictionary(my_dict) in a list (L1)
print(L1)
num=int(input("enter number of betweenness centrality nodes:"))
print("Nodes with highest betweenness centrality nodes: ",end="")
for i in L1[0:num]:
  betweenness_centrality=(my_dict.get(i))            #using the nodes stored in the list(L1) to call the values from dictionary(my_dict)
  print(f"({i}:{betweenness_centrality}) ",end="")
print("\naverage_shortest_path_length: ",nx.average_shortest_path_length(G))
print("average_clustering: ",nx.average_clustering(G))

pop_L1=[]                                           #storing once again the node numbers of L1 in pop_L1 so to use them to pop out the values
for k in L1[0:num]:
  pop_L1.append(k)
Hnode_list=[]
for u1 in L1[0:num]:
  for v1 in pop_L1[1:num]:
    m1=(u1,v1)
    m2=(v1,u1)
    Hnode_list.append(m1)
    Hnode_list.append(m2)
  if len(pop_L1)>1:
    pop_L1.pop(1)
print("Hnode_list",Hnode_list)
H_dist={}
for z1 in range(0,len(Hnode_list)):
  H1=dist_dict.get(Hnode_list[z1])
  #print(H1)
  if H1!= None:
    H_dist.update({Hnode_list[z1]:H1})
print("H_dist",H_dist)
S_D=sorted(H_dist.items(),key=operator.itemgetter(1),reverse=True)      #arranging dist_dict values in descinding order to get the nodes with highest distances
p_dict=dict(S_D)
L_q=list(p_dict.keys())
print("Nodes with highest distances: ",end="")
s=[]                               #storing node pairs with highest distances
for r in L_q[0:num//2]:
  dist=(p_dict.get(r))
  s.append(r)
  print(f"({r}:{dist}) ",end="")
print()
print("nodes with highest distance",s)
for i5 in G.edges():
    G[i5[0]][i5[1]]['color'] = 'c'
for i6 in s[0:num//2]:
  G.add_edge(*i6)
  G[i6[0]][i6[1]]['color'] = 'r'
  print("average_shortest_path_length: ",nx.average_shortest_path_length(G))
  print("average_clustering: ",nx.average_clustering(G))
Hcolors = [ G[i5[0]][i5[1]]['color'] for i5 in G.edges() ]
plt.figure(figsize=(10,10))
nx.draw(G,pos,node_size=200,edge_color=Hcolors,font_size=10,with_labels=1,node_color="g")
plt.axis('on')
print("edges",len(G.edges()))

"""# calculating avg path length,avg clustring coffecient
5x5 graph ,adding shortest edges,**adding shortest edges**,adding long range links
according to top 20 nodes of  highest distances
**without betweeness centrality measurement**
"""

import networkx as nx
import matplotlib.pyplot as plt
import random
import operator
import math
G=nx.random_geometric_graph(100,.3)
pos = nx.get_node_attributes(G,'pos')
print("coordinates before development",pos)
                                               #improving coordinates
for n in pos:
  x,y=pos[n]
  if x<1:
    dx=x+random.randint(1,4999)
    dy=y+random.randint(1,4999)
    a=[dx,dy]
    pos.update({n:a})
print("coordinates after development",pos)
print("edges",len(G.edges()))
nx.draw(G,pos,node_size=200,font_size=10,with_labels=1,node_color="g")
plt.axis('on')
                                                 #finding distances between nodes
Xlist=[]
p_Xlist=[]
Ylist=[]
p_Ylist=[]
for n1 in pos:
  x,y=pos[n1]
  Xlist.append(x)
  p_Xlist.append(x)
  Ylist.append(y)
  p_Ylist.append(y)
c=[]                           #storing calculated values of first part of distance formula in c list
for x1 in Xlist[0:len(Xlist)]:
  for x2 in p_Xlist[1:len(p_Xlist)]:
    a=math.pow((x2-x1),2)
    c.append(a)
  if len(p_Xlist)>1: #condition is given because anynumber in xlist is calculated with the numbers which are coming after that number same expalination for all this type of conditions in whole code
    p_Xlist.pop(1)
d=[]                                       #storing calculated values of second part of distance formula in d list
for y1 in Ylist[0:len(Ylist)]:
  for y2 in p_Ylist[1:len(p_Ylist)]:
    b=math.pow((y2-y1),2)
    d.append(b)
  if len(p_Ylist)>1:
    p_Ylist.pop(1)
dist_value=[]
for e in range(0,len(c)):
  distance=math.sqrt(c[e]+d[e])   #distance=sqrt(x2-x1)^2+(y2-y1)^2)    #distance=math.sqrt(math.pow((x2-x1),2)+math.pow((y2-y1),2))
  dist_value.append(distance)
print("dist_value",dist_value)
print("dist_value",len(dist_value))
k=[]
pop_k=[]                                   #storing the node numbers of pos in pop_k so to use them to pop out the values
for n2 in pos:
  k.append(n2)
  pop_k.append(n2)
node_list=[]                           #storing node pairs such that 1st node and 2nd node in a list are taken in tuple
for u in k:
  for v in pop_k[1:len(pop_k)]:
    m=(u,v)
    node_list.append(m)
  if len(pop_k)>1:
    pop_k.pop(1)
print(len(node_list))
dist_dict={}                      #storing the node pairs as keys and distances as values
for z in range(0,len(node_list)):
  dist_dict.update({node_list[z]:dist_value[z]})
print("dist_dict",dist_dict)
for i4 in G.edges():                                     #adding color
    G[i4[0]][i4[1]]['color'] = 'y'
for n3 in dist_dict:                                     #adding shortest edges between nodes
  value=dist_dict.get(n3)
  if value>1000 and G.has_edge(*n3) is True:
    G.remove_edge(*n3)
  if value<1000 and G.has_edge(*n3) is False:
    G.add_edge(*n3)
    G[n3[0]][n3[1]]['color'] = 'r'
colors = [ G[i4[0]][i4[1]]['color'] for i4 in G.edges() ]
print("\naverage_shortest_path_length: ",nx.average_shortest_path_length(G))
print("average_clustering: ",nx.average_clustering(G))
plt.figure(figsize=(10,10))
nx.draw(G,pos,node_size=200,edge_color=colors,font_size=10,with_labels=1,node_color="g")
plt.axis('on')
S_D=sorted(dist_dict.items(),key=operator.itemgetter(1),reverse=True) #arranging dist_dict values in descinding order to get the nodes with highest distances
p_dict=dict(S_D)
L_q=list(p_dict.keys())
print("Nodes with highest distances: ",end="")
num=int(input("enter number of betweenness centrality nodes:"))
s=[]                #storing node pairs with highest distances
for r in L_q[0:num//2]:
  dist=(p_dict.get(r))
  s.append(r)
  print(f"({r}:{dist}) ",end="")
print()
print("nodes with highest distance",s)
for i5 in G.edges():
    G[i5[0]][i5[1]]['color'] = 'c'
for i6 in s[0:num//2]:
  G.add_edge(*i6)
  G[i6[0]][i6[1]]['color'] = 'r'
  print("average_shortest_path_length: ",nx.average_shortest_path_length(G))
  print("average_clustering: ",nx.average_clustering(G))
Hcolors = [ G[i5[0]][i5[1]]['color'] for i5 in G.edges() ]
plt.figure(figsize=(10,10))
nx.draw(G,pos,node_size=200,edge_color=Hcolors,font_size=10,with_labels=1,node_color="g")
plt.axis('on')
print("edges",len(G.edges()))

"""# **watts_strogatz_graph**
# calculating avg path length,avg clustring coffecient
5x5 graph,adding long range links according to top 20 nodes of highest distances

**without betweeness centrality measurement**
"""

import networkx as nx
import matplotlib.pyplot as plt
import random
G = nx.watts_strogatz_graph(n=748,k=7,p=0.9)
print(G.nodes)
print(G)
a=G.nodes
for i in a:
  a.remove(i)
pos =nx.circular_layout(G)             #nx.fruchterman_reingold_layout(G)
print(pos)
'''print("average_shortest_path_length: ",nx.average_shortest_path_length(G))
print("average_clustering: ",nx.average_clustering(G))
nx.draw(G,node_size=200,font_size=10,with_labels=1,node_color="b")'''

import networkx as nx
import matplotlib.pyplot as plt
import random
G = nx.watts_strogatz_graph(n=100,k=2,p=0.3)
pos =nx.circular_layout(G)             #nx.fruchterman_reingold_layout(G)
nx.draw(G,pos,node_size=200,font_size=10,with_labels=1,node_color="b")
print(pos)
for n in pos:
  x,y=pos[n]
  if x<1:
    dx=x+random.randint(1,4999)
    dy=y+random.randint(1,4999)
    a=[dx,dy]
    pos.update({n:a})
print("coordinates after development",pos)
print("average_shortest_path_length: ",nx.average_shortest_path_length(G))
print("average_clustering: ",nx.average_clustering(G))
plt.figure(figsize=(5,5))
nx.draw(G,pos,node_size=200,font_size=10,with_labels=1,node_color="b")
print("edges",len(G.edges()))
                                               #finding distances between nodes
Xlist=[]
p_Xlist=[]
Ylist=[]
p_Ylist=[]
for n1 in pos:
  x,y=pos[n1]
  Xlist.append(x)
  p_Xlist.append(x)
  Ylist.append(y)
  p_Ylist.append(y)
c=[]                                      #storing calculated values of first part of distance formula in c list
for x1 in Xlist[0:len(Xlist)]:
  for x2 in p_Xlist[1:len(p_Xlist)]:
    a=math.pow((x2-x1),2)                         #first part of distance formula
    c.append(a)
  if len(p_Xlist)>1: #condition is given because anynumber in xlist is calculated with the numbers which are coming after that number same expalination for all this type of conditions in whole code
    p_Xlist.pop(1)
d=[]                                     #storing calculated values of second part of distance formula in d list
for y1 in Ylist[0:len(Ylist)]:
  for y2 in p_Ylist[1:len(p_Ylist)]:
    b=math.pow((y2-y1),2)                       #second part of distance formula
    d.append(b)
  if len(p_Ylist)>1:
    p_Ylist.pop(1)
dist_value=[]
for e in range(0,len(c)):
  distance=math.sqrt(c[e]+d[e])   #distance=sqrt(x2-x1)^2+(y2-y1)^2)    #distance=math.sqrt(math.pow((x2-x1),2)+math.pow((y2-y1),2))
  dist_value.append(distance)
print("dist_value",dist_value)
print("dist_value",len(dist_value))
k=[]
pop_k=[]                           #storing the node numbers of pos in pop_k so to use them to pop out the values
for n2 in pos:
  k.append(n2)
  pop_k.append(n2)
node_list=[]                   #storing node pairs such that 1st node and 2nd node in a list are taken in tuple
for u in k:
  for v in pop_k[1:len(pop_k)]:
    m=(u,v)
    node_list.append(m)
  if len(pop_k)>1:
    pop_k.pop(1)
print(len(node_list))
dist_dict={}                    #storing the node pairs as keys and distances as values
for z in range(0,len(node_list)):
  dist_dict.update({node_list[z]:dist_value[z]})
print("dist_dict",dist_dict)
S_D=sorted(dist_dict.items(),key=operator.itemgetter(1),reverse=True)         #arranging dist_dict values in descinding order to get the nodes with highest distances
p_dict=dict(S_D)
L_q=list(p_dict.keys())
print("Nodes with highest distances: ",end="")
num=int(input("enter number of betweenness centrality nodes:"))
s=[]                   #storing node pairs with highest distances
for r in L_q[0:num//2]:
  dist=(p_dict.get(r))
  s.append(r)
  print(f"({r}:{dist}) ",end="")
print()
print("nodes with highest distance",s)
for i5 in G.edges():
    G[i5[0]][i5[1]]['color'] = 'y'
for i6 in s[0:num//2]:
  G.add_edge(*i6)
  G[i6[0]][i6[1]]['color'] = 'r'
  print("average_shortest_path_length: ",nx.average_shortest_path_length(G))
  print("average_clustering: ",nx.average_clustering(G))
Hcolors = [ G[i5[0]][i5[1]]['color'] for i5 in G.edges() ]
plt.figure(figsize=(10,10))
nx.draw(G,pos,node_size=200,edge_color=Hcolors,font_size=10,with_labels=1,node_color="b")
plt.axis('on')
print("edges",len(G.edges()))

"""# watts_strogatz_graph
# calculating avg path length,avg clustring coffecient
5x5 graph,adding long range links according to top 20 nodes of beweeness centrality and highest distances
"""

import networkx as nx
import matplotlib.pyplot as plt
import random
G = nx.watts_strogatz_graph(n=100,k=4,p=0.3)
pos =nx.circular_layout(G)             #nx.fruchterman_reingold_layout(G)
nx.draw(G,pos,node_size=200,font_size=10,with_labels=1,node_color="b")
print(pos)
for n in pos:
  x,y=pos[n]
  if x<1:
    dx=x+random.randint(1,4999)
    dy=y+random.randint(1,4999)
    a=[dx,dy]
    pos.update({n:a})
print("coordinates after development",pos)
print("average_shortest_path_length: ",nx.average_shortest_path_length(G))
print("average_clustering: ",nx.average_clustering(G))
plt.figure(figsize=(5,5))
nx.draw(G,pos,node_size=200,font_size=10,with_labels=1,node_color="b")
print("edges",len(G.edges()))


D=nx.betweenness_centrality(G)                    #Finding betweeness centrality
print("betweenness_centrality:",D)
SD=sorted(D.items(),key=operator.itemgetter(1),reverse=True)     #arranging betweeness centrality values in descending order
my_dict=dict(SD)                  #converting SD into dictionary
L1=list(my_dict.keys())                  #storing the keys(nodes) of dictionary(my_dict) in a list (L1)
print(L1)
num=int(input("enter number of betweenness centrality nodes:"))
print("Nodes with highest betweenness centrality nodes: ",end="")
for i in L1[0:num]:
  betweenness_centrality=(my_dict.get(i))
  print(f"({i}:{betweenness_centrality}) ",end="")            #using the nodes stored in the list(L1) to call the values from dictionary(my_dict)
print("\naverage_shortest_path_length: ",nx.average_shortest_path_length(G))
print("average_clustering: ",nx.average_clustering(G))
                                          #finding highest distances between top nodes
Xlist=[]
p_Xlist=[]
Ylist=[]
p_Ylist=[]
for w in L1[0:num]:
  x,y=pos[w]
  Xlist.append(x)
  p_Xlist.append(x)
  Ylist.append(y)
  p_Ylist.append(y)
c=[]                                           #storing calculated values of first part of distance formula in c list
for x1 in Xlist[0:len(Xlist)]:
  for x2 in p_Xlist[1:len(p_Xlist)]:
    a=math.pow((x2-x1),2)
    c.append(a)
  if len(p_Xlist)>1:                #condition is given because anynumber in xlist is calculated with the numbers which are coming after that number same expalination for all this type of conditions in whole code
    p_Xlist.pop(1)
d=[]                                                                   #storing calculated values of second part of distance formula in d list
for y1 in Ylist[0:len(Ylist)]:
  for y2 in p_Ylist[1:len(p_Ylist)]:
    b=math.pow((y2-y1),2)
    d.append(b)
  if len(p_Ylist)>1:
    p_Ylist.pop(1)
dist_value=[]
for e in range(0,len(c)):
  distance=math.sqrt(c[e]+d[e])   #distance=sqrt(x2-x1)^2+(y2-y1)^2)    #distance=math.sqrt(math.pow((x2-x1),2)+math.pow((y2-y1),2))
  dist_value.append(distance)
print("dist_value",dist_value)
pop_L1=[]                                                #storing once again the node numbers of L1 in pop_L1 so to use them to pop out the values
for k in L1[0:num]:
  pop_L1.append(k)
node_list=[]                    #storing node pairs such that 1st node and 2nd node in a list are taken in tuple
for u in L1[0:num]:
  for v in pop_L1[1:num]:
    m=(u,v)
    node_list.append(m)
  if len(pop_L1)>1:
    pop_L1.pop(1)
dist_dict={}                   #storing the node pairs as keys and distances as values
for z in range(0,len(node_list)):
  dist_dict.update({node_list[z]:dist_value[z]})
print("dist_dict",dist_dict)
S_D=sorted(dist_dict.items(),key=operator.itemgetter(1),reverse=True)              #arranging dist_dict values in descinding order to get the nodes with highest distances
p_dict=dict(S_D)
L_q=list(p_dict.keys())
print("Nodes with highest distances: ",end="")
s=[]                              #storing node pairs with highest distances
for r in L_q[0:num//2]:
  dist=(p_dict.get(r))
  s.append(r)
  print(f"({r}:{dist}) ",end="")
print()
print("nodes with highest distance",s)
for i5 in G.edges():
    G[i5[0]][i5[1]]['color'] = 'y'
for i6 in s[0:num//2]:
  G.add_edge(*i6)
  G[i6[0]][i6[1]]['color'] = 'r'
  print("average_shortest_path_length: ",nx.average_shortest_path_length(G))
  print("average_clustering: ",nx.average_clustering(G))
Hcolors = [ G[i5[0]][i5[1]]['color'] for i5 in G.edges() ]
plt.figure(figsize=(10,10))
nx.draw(G,pos,node_size=200,edge_color=Hcolors,font_size=10,with_labels=1,node_color="b")
plt.axis('on')
print("edges",len(G.edges()))

"""# calculating avg path length,avg clustring coffecient
5x5 graph ,adding long range links
according to nodes of betweenness centrality and highest distances
"""

import networkx as nx
import matplotlib.pyplot as plt
import random
import operator
import math
G=nx.random_geometric_graph(100,.3)
pos = nx.get_node_attributes(G,'pos')
print("coordinates before development",pos)
                                     #improving coordinates to 5x5
for n in pos:
  x,y=pos[n]
  if x<1:
    dx=x+random.randint(1,4999)
    dy=y+random.randint(1,4999)
    a=[dx,dy]
    pos.update({n:a})
print("coordinates after development",pos)

                                                 #4. Finding betweeness centrality
D=nx.betweenness_centrality(G)
print("betweenness_centrality:",D)
SD=sorted(D.items(),key=operator.itemgetter(1),reverse=True)    #arranging betweeness centrality values in descending order
my_dict=dict(SD)                 #converting SD into dictionary
L1=list(my_dict.keys())          #storing the keys(nodes) of dictionary(my_dict) in a list (L1)
num=int(input("enter number of betweenness centrality nodes:"))
print("Nodes with highest betweenness centrality nodes: ",end="")
for i in L1[0:num]:
  betweenness_centrality=(my_dict.get(i))            #using the nodes stored in the list(L1) to call the values from dictionary(my_dict)
  print(f"({i}:{betweenness_centrality}) ",end="")
print("\naverage_shortest_path_length: ",nx.average_shortest_path_length(G))
print("average_clustering: ",nx.average_clustering(G))
nx.draw(G,pos,node_size=200,font_size=10,with_labels=1,node_color="g")
plt.axis('on')

                                          #finding highest distances between top nodes
Xlist=[]                           #storing x-coordinate values in list(Xlist)
p_Xlist=[]                         #again storing x-coordinate values in list(p_Xlist)
Ylist=[]                           #storing y-coordinate values in list(Ylist)
p_Ylist=[]                         #again storing y-coordinate values in list(p_Ylist)
for w in L1[0:num]:
  x,y=pos[w]                      #assining x,y coordinate values in  pos to variables x,y
  Xlist.append(x)                  #appending vlaues
  p_Xlist.append(x)
  Ylist.append(y)
  p_Ylist.append(y)
c=[]                                            #storing calculated values of first part of distance formula in c list
for x1 in Xlist[0:len(Xlist)]:
  for x2 in p_Xlist[1:len(p_Xlist)]:
    a=math.pow((x2-x1),2)
    c.append(a)
  if len(p_Xlist)>1:                           #condition is given because anynumber in xlist is calculated with the numbers which are coming after that number same expalination for all this type of conditions in whole code
    p_Xlist.pop(1)
d=[]                                           #storing calculated values of second part of distance formula in d list
for y1 in Ylist[0:len(Ylist)]:
  for y2 in p_Ylist[1:len(p_Ylist)]:
    b=math.pow((y2-y1),2)
    d.append(b)
  if len(p_Ylist)>1:
    p_Ylist.pop(1)
dist_value=[]                                 #storing  distance values
for e in range(0,len(c)):
  distance=math.sqrt(c[e]+d[e])   #distance=sqrt(x2-x1)^2+(y2-y1)^2)    #distance=math.sqrt(math.pow((x2-x1),2)+math.pow((y2-y1),2))
  dist_value.append(distance)
print("dist_value",dist_value)
pop_L1=[]                                    #storing once again the node numbers of L1 in pop_L1 so to use them to pop out the values
for k in L1[0:num]:
  pop_L1.append(k)
node_list=[]                                #storing node pairs such that 1st node and 2nd node in a list are taken in tuple
for u in L1[0:num]:
  for v in pop_L1[1:num]:
    m=(u,v)
    node_list.append(m)
  if len(pop_L1)>1:
    pop_L1.pop(1)
dist_dict={}                               #storing the node pairs as keys and distances as values
for z in range(0,len(node_list)):
  dist_dict.update({node_list[z]:dist_value[z]})
print("dist_dict",dist_dict)
S_D=sorted(dist_dict.items(),key=operator.itemgetter(1),reverse=True)        #arranging dist_dict values in descinding order to get the nodes with highest distances
p_dict=dict(S_D)
L_q=list(p_dict.keys())
print("Nodes with highest distances: ",end="")
s=[]                                                    #storing node pairs with highest distances
for r in L_q[0:num//2]:
  dist=(p_dict.get(r))
  s.append(r)
  print(f"({r}:{dist}) ",end="")
print()
print("nodes with highest distance",s)
H_node=[]                                          #storing unpaked node pairs with highest distances
for t in s[0:len(s)]:
  tup=t
  H_node.append(tup[0])
  H_node.append(tup[1])
L2=[] #contains odd position vlaues of H_node
for i1 in H_node[0:num:2]:
  L2.append(i1)
L3=[] #contains even position values of H_node
for i2 in H_node[1:num:2]:
  L3.append(i2)
for i4 in G.edges():
    G[i4[0]][i4[1]]['color'] = 'y'             #giving color to all edges
for i3 in range(0,num//2):
  G.add_edge(L2[i3],L3[i3])
  G[L2[i3]][L3[i3]]['color'] = 'r'                #giving color to added edges
  print("average_shortest_path_length: ",nx.average_shortest_path_length(G))
  print("average_clustering: ",nx.average_clustering(G))
colors = [ G[i4[0]][i4[1]]['color'] for i4 in G.edges() ]  #storing all different color of edges in variable (colors)
plt.figure(figsize=(10,10))
nx.draw(G,pos,node_size=200,edge_color=colors,font_size=10,with_labels=1,node_color="g")
plt.axis('on')
print("edges",len(G.edges()))

"""# problem

"""

import networkx as nx
import matplotlib.pyplot as plt
import random
import operator
import math
G=nx.random_geometric_graph(350,.1)
pos = nx.get_node_attributes(G,'pos')
print("coordinates before development",pos)
                                               #improving coordinates
for n in pos:
  x,y=pos[n]
  if x<1:
    dx=x+random.randint(1,4999)
    dy=y+random.randint(1,4999)
    a=[dx,dy]
    pos.update({n:a})
print("coordinates after development",pos)
                                                #finding distances between nodes
Xlist=[]
p_Xlist=[]
Ylist=[]
p_Ylist=[]
for n1 in pos:
  x,y=pos[n1]
  Xlist.append(x)
  p_Xlist.append(x)
  Ylist.append(y)
  p_Ylist.append(y)
c=[]                                            #storing calculated values of first part of distance formula in c list
for x1 in Xlist[0:len(Xlist)]:
  for x2 in p_Xlist[1:len(p_Xlist)]:
    a=math.pow((x2-x1),2)
    c.append(a)
  if len(p_Xlist)>1:        #condition is given because anynumber in xlist is calculated with the numbers which are coming after that number same expalination for all this type of conditions in whole code
    p_Xlist.pop(1)
d=[]                                                                      #storing calculated values of second part of distance formula in d list
for y1 in Ylist[0:len(Ylist)]:
  for y2 in p_Ylist[1:len(p_Ylist)]:
    b=math.pow((y2-y1),2)
    d.append(b)
  if len(p_Ylist)>1:
    p_Ylist.pop(1)
dist_value=[]
for e in range(0,len(c)):
  distance=math.sqrt(c[e]+d[e])   #distance=sqrt(x2-x1)^2+(y2-y1)^2)    #distance=math.sqrt(math.pow((x2-x1),2)+math.pow((y2-y1),2))
  dist_value.append(distance)
#print("dist_value",dist_value)
#print("dist_value",len(dist_value))
k=[]
pop_k=[]                                            #storing the node numbers of pos in pop_k so to use them to pop out the values
for n2 in pos:
  k.append(n2)
  pop_k.append(n2)
node_list=[]                                     #storing node pairs such that 1st node and 2nd node in a list are taken in tuple
for u in k:
  for v in pop_k[1:len(pop_k)]:
    m=(u,v)
    node_list.append(m)
  if len(pop_k)>1:
    pop_k.pop(1)
#print("node_list",len(node_list))
dist_dict={}                                         #storing the node pairs as keys and distances as values
for z in range(0,len(node_list)):
  dist_dict.update({node_list[z]:dist_value[z]})
#print("dist_dict",dist_dict)
nx.draw(G,pos,node_size=200,font_size=10,with_labels=1,node_color="g")
plt.axis('on')
for i4 in G.edges():                                     #adding color
    G[i4[0]][i4[1]]['color'] = 'y'
for n3 in dist_dict:                                     #adding shortest edges between nodes
  value=dist_dict.get(n3)
  if value>500 and G.has_edge(*n3) is True:            #unpacks
    G.remove_edge(*n3)
  if value<500 and G.has_edge(*n3) is False:
    G.add_edge(*n3)
    G[n3[0]][n3[1]]['color'] = 'r'
colors = [ G[i4[0]][i4[1]]['color'] for i4 in G.edges() ]
plt.figure(figsize=(10,10))
nx.draw(G,pos,node_size=200,edge_color=colors,font_size=10,with_labels=1,node_color="g")
plt.axis('on')
D=nx.betweenness_centrality(G)    #D=dict(G.degree())                #Finding betweeness centrality
print("betweenness_centrality:",D)
SD=sorted(D.items(),key=operator.itemgetter(1),reverse=True)    #arranging betweeness centrality values in descending order
my_dict=dict(SD)                             #converting SD into dictionary
L1=list(my_dict.keys())                      #storing the keys(nodes) of dictionary(my_dict) in a list (L1)
#print(L1)
num=int(input("enter number of betweenness centrality nodes:"))
print("Nodes with highest betweenness centrality nodes: ",end="")
for i in L1[0:num]:
  betweenness_centrality=(my_dict.get(i))            #using the nodes stored in the list(L1) to call the values from dictionary(my_dict)
  print(f"({i}:{betweenness_centrality}) ",end="")
print("\naverage_shortest_path_length: ",nx.average_shortest_path_length(G))
print("average_clustering: ",nx.average_clustering(G))
pop_L1=[]                                           #storing once again the node numbers of L1 in pop_L1 so to use them to pop out the values
for k in L1[0:num]:
  pop_L1.append(k)
Hnode_list=[]                   #contains descending order betweeness centrality nodes as paired
for u1 in L1[0:num]:
  for v1 in pop_L1[1:num]:
    m1=(u1,v1)
    m2=(v1,u1)
    Hnode_list.append(m1)
    Hnode_list.append(m2)
  if len(pop_L1)>1:
    pop_L1.pop(1)
#print("Hnode_list",Hnode_list)
H_dist={}                             #it contains highest betweeness centrality node pairs with distances
for z1 in range(0,len(Hnode_list)):
  H1=dist_dict.get(Hnode_list[z1])
  #print(H1)
  if H1!= None:
    H_dist.update({Hnode_list[z1]:H1})
#print("H_dist",H_dist)
S_D=sorted(H_dist.items(),key=operator.itemgetter(1),reverse=True)      #arranging H_dist values(distances) in descinding order to get the nodes with highest distances
p_dict=dict(S_D)
L_q=list(p_dict.keys())
print("Nodes with highest distances: ",end="")
s={}                               #storing node pairs with highest distances
for r in L_q[0:num//2]:
  dist=(p_dict.get(r))
  s.update({r:dist})
  print(f"({r}:{dist}) ",end="")
print()
for i5 in G.edges():
    G[i5[0]][i5[1]]['color'] = 'c'
                                        #analysis of average_shortest_path_length

L_edge=[]         #it contain average_shortest_path_length values which are usefull in comparision
F_edge=[]         # it will contains all the edges which are going to from long range links for analysis
no_of_LRlinks=[]
for n5 in s:
  if G.has_edge(*n5) is False:
    F_edge.append(n5)
    G.add_edge(*n5)
    G[n5[0]][n5[1]]['color'] = 'r'
    L_edge.append(nx.average_shortest_path_length(G))
    print("L_edge",L_edge)
    if F_edge[0]!=n5 and round(L_edge[0],10)!=round(nx.average_shortest_path_length(G),10) and math.floor(L_edge[0]*10)/10==math.floor(nx.average_shortest_path_length(G)*10)/10:
      G.remove_edge(*n5)
      pass
    else:
      #print(f"({n5}:{nx.shortest_path(G,*n5)})")
      no_of_LRlinks.append(n5)
      print(n5,":average_shortest_path_length: ",nx.average_shortest_path_length(G))
      print("\taverage_clustering: ",nx.average_clustering(G))
    if F_edge[0]!=n5:
      L_edge.pop(0)
print("node pairs that have particepated in forming long range links",F_edge)
print("final node pairs which has new edges:",len(no_of_LRlinks))
H_colors = [ G[m1[0]][m1[1]]['color'] for m1 in G.edges() ]
plt.figure(figsize=(10,10))
nx.draw(G,pos,node_size=200,edge_color=H_colors,font_size=10,with_labels=1,node_color="g")
plt.axis('on')
print("total edges",len(G.edges()))

"""# **Testing watts_strogatz_graph**"""

import networkx as nx
import matplotlib.pyplot as plt
G = nx.watts_strogatz_graph(n=50,k=4,p=0.6)
pos = nx.circular_layout(G) #nx.fruchterman_reingold_layout(G)
print(pos)
nx.draw(G,pos,node_size=100,font_size=5,with_labels=1,node_color="b",alpha=1,width=5)

D=dict(G.degree()) #1.Finding degree
D=nx.degree_centrality(G) #2.Finding Degree centrality
D=nx.closeness_centrality(G) #3.Finding closeness centrality
D=nx.betweenness_centrality(G) #4. Finding betweeness centrality

"""# **Testing methodes to decrease avg path length**

# **final code**
"""

import networkx as nx
import matplotlib.pyplot as plt
import random
import operator
import math
def function(D):
  print(D)
  SD=sorted(D.items(),key=operator.itemgetter(1),reverse=True)    #arranging degree values in descending order
  my_dict=dict(SD)                             #converting SD into dictionary
  L1=list(my_dict.keys())                      #storing the keys(nodes) of dictionary(my_dict) in a list (L1)
  #print(len(L1))
  #print(L1)
  print("values of Nodes in descending order : ",end="")
  print(my_dict)
  pop_L1=[]                                           #storing once again the node numbers of L1 in pop_L1 so to use them to pop out the values
  for k in L1:
    pop_L1.append(k)
  N_list=[]
  for u1 in L1:
    for v1 in pop_L1[1:len(pop_L1)]:
      m1=(u1,v1)
      N_list.append(m1)
    if len(pop_L1)>1:
      pop_L1.pop(1)
  print("no.of node pairs which are their:",len(N_list))
  NUM=int(input("enter number of node pairs for evaluation:"))
  Hnode_list=[]
  for u2 in N_list[0:NUM]:
    Hnode_list.append(u2)
  num=int(input("enter number of node pairs you want:"))
  for i5 in G.edges():
      G[i5[0]][i5[1]]['color'] = 'c'
                                          #analysis of average_shortest_path_length

  L_edge=[]         #it contain average_shortest_path_length values which are usefull in comparision
  print("####results of convensional graph####")
  print("average_shortest_path_length: ",nx.average_shortest_path_length(G))
  L_edge.append(nx.average_shortest_path_length(G))
  print("average_clustering: ",nx.average_clustering(G))
  print("####results after applying methode####")
  F_edge=[]         # it will contains all the edges which are going to from long range links for analysis
  no_of_LRlinks=[]
  for n5 in Hnode_list:
    if G.has_edge(*n5) is False:
      F_edge.append(n5)
      G.add_edge(*n5)
      L_edge.append(nx.average_shortest_path_length(G))
      print("L_edge",L_edge)
      if math.floor(L_edge[0]*10)/10==math.floor(nx.average_shortest_path_length(G)*10)/10:      # round(L_edge[0],10)!=round(nx.average_shortest_path_length(G),10) and
        G.remove_edge(*n5)
        pass
      else:
        G[n5[0]][n5[1]]['color'] = 'r'
        no_of_LRlinks.append(n5)
        print(n5,":average_shortest_path_length: ",nx.average_shortest_path_length(G))
        print("\taverage_clustering: ",nx.average_clustering(G))
      #if F_edge[0]!=n5:
      L_edge.pop(0)
    if len(no_of_LRlinks)==num:
      break
  print("node pairs that have particepated in forming long range links",F_edge,"=",len(F_edge))
  print("final node pairs which has new edges:",len(no_of_LRlinks))
  H_colors = [ G[m1[0]][m1[1]]['color'] for m1 in G.edges() ]
  plt.figure(figsize=(10,10))
  nx.draw(G,pos,node_size=200,edge_color=H_colors,font_size=10,with_labels=1,node_color="g")
  plt.axis('on')
  print("total edges",len(G.edges()))
  G.remove_edges_from(no_of_LRlinks)
  plt.figure(figsize=(10,10))
  nx.draw(G,pos,node_size=200,font_size=10,with_labels=1,node_color="g")
  plt.axis('on')
  print("total edges",len(G.edges()))
#####################################################################################
G=nx.random_geometric_graph(350,.6)
pos = nx.get_node_attributes(G,'pos')
print("coordinates before development",pos)
                                               #improving coordinates
for n in pos:
  x,y=pos[n]
  dx=x+random.randint(1,4999)
  dy=y+random.randint(1,4999)
  a=[dx,dy]
  pos.update({n:a})
print("coordinates after development",pos)
                                                #finding distances between nodes
Xlist=[]
p_Xlist=[]
Ylist=[]
p_Ylist=[]
for n1 in pos:
  x,y=pos[n1]
  Xlist.append(x)
  p_Xlist.append(x)
  Ylist.append(y)
  p_Ylist.append(y)
c=[]                                            #storing calculated values of first part of distance formula in c list
for x1 in Xlist[0:len(Xlist)]:
  for x2 in p_Xlist[1:len(p_Xlist)]:
    a=math.pow((x2-x1),2)
    c.append(a)
  if len(p_Xlist)>1:        #condition is given because anynumber in xlist is calculated with the numbers which are coming after that number same expalination for all this type of conditions in whole code
    p_Xlist.pop(1)
d=[]                                                                      #storing calculated values of second part of distance formula in d list
for y1 in Ylist[0:len(Ylist)]:
  for y2 in p_Ylist[1:len(p_Ylist)]:
    b=math.pow((y2-y1),2)
    d.append(b)
  if len(p_Ylist)>1:
    p_Ylist.pop(1)
dist_value=[]
for e in range(0,len(c)):
  distance=math.sqrt(c[e]+d[e])   #distance=sqrt(x2-x1)^2+(y2-y1)^2)    #distance=math.sqrt(math.pow((x2-x1),2)+math.pow((y2-y1),2))
  dist_value.append(distance)
#print("dist_value",dist_value)
#print("dist_value",len(dist_value))
pop_k=[]                                            #storing the node numbers of pos in pop_k so to use them to pop out the values
for n2 in pos:
  pop_k.append(n2)
node_list=[]                                     #storing node pairs such that 1st node and 2nd node in a list are taken in tuple
for u in pos:
  for v in pop_k[1:len(pop_k)]:
    m=(u,v)
    node_list.append(m)
  if len(pop_k)>1:
    pop_k.pop(1)
#print("node_list",len(node_list))
dist_dict={}                                         #storing the node pairs as keys and distances as values
for z in range(0,len(node_list)):
  dist_dict.update({node_list[z]:dist_value[z]})
print("dist_dict",len(dist_dict))
nx.draw(G,pos,node_size=200,font_size=10,with_labels=1,node_color="g")
plt.axis('on')
for i4 in G.edges():                                     #adding color
    G[i4[0]][i4[1]]['color'] = 'y'
for n3 in dist_dict:                                     #adding shortest edges between nodes
  value=dist_dict.get(n3)
  if value>500 and G.has_edge(*n3) is True:            #unpacks
    G.remove_edge(*n3)
  if value<500 and G.has_edge(*n3) is False:
    G.add_edge(*n3)
    G[n3[0]][n3[1]]['color'] = 'r'
colors = [ G[i4[0]][i4[1]]['color'] for i4 in G.edges() ]
plt.figure(figsize=(10,10))
nx.draw(G,pos,node_size=200,edge_color=colors,font_size=10,with_labels=1,node_color="g")
plt.axis('on')
#print("average_shortest_path_length: ",nx.average_shortest_path_length(G))
#print("average_clustering: ",nx.average_clustering(G))
print("**************************nx.degree*******************************************")
function(dict(nx.degree(G)))
print("************************nx.degree_centrality**********************************")
function(nx.degree_centrality(G))
print("***********************nx.closeness_centrality********************************")
function(nx.closeness_centrality(G))
print("***********************nx.betweenness_centrality******************************")
function(nx.betweenness_centrality(G))

print("total edges",len(G.edges()))
for n4 in G.edges():
    G[n4[0]][n4[1]]['color'] = 'c'
sp=[]
for r1 in dist_dict:
  sp.append(len(nx.shortest_path(G,*r1)))
print("length of max intermideate nodes containing list:",max(sp))
print("length of min intermideate nodes containing list:",min(sp))
num=int(input("enter number of node pairs:"))
L_edge=[]         #it contain average_shortest_path_length values which are usefull in comparision
print("####results of convensional graph####")
print("average_shortest_path_length: ",nx.average_shortest_path_length(G))
L_edge.append(nx.average_shortest_path_length(G))
print("average_clustering: ",nx.average_clustering(G))
print("####results after applying methodes####")
F_edge=[]
no_of_LRlinks=[]
for n5 in dist_dict:
  value=dist_dict.get(n5)
  if value>3000 and G.has_edge(*n5) is False and len(nx.shortest_path(G,*n5))>=max(sp)//2:
    F_edge.append(n5)
    G.add_edge(*n5)
    L_edge.append(nx.average_shortest_path_length(G))
    print("L_edge",L_edge)
    if math.floor(L_edge[0]*10)/10==math.floor(nx.average_shortest_path_length(G)*10)/10:      #and round(L_edge[0],10)!=round(nx.average_shortest_path_length(G),10)
      G.remove_edge(*n5)
      pass
    else:
      G[n5[0]][n5[1]]['color'] = 'r'
      no_of_LRlinks.append(n5)
      print(n5,":average_shortest_path_length: ",nx.average_shortest_path_length(G))
      print("\taverage_clustering: ",nx.average_clustering(G))
    L_edge.pop(0)
  if len(no_of_LRlinks)==num:
    break
print("node pairs that have particepated in forming long range links",F_edge,"=",len(F_edge))
print("final node pairs which has new edges:",len(no_of_LRlinks))
H_colors = [ G[m1[0]][m1[1]]['color'] for m1 in G.edges() ]
plt.figure(figsize=(10,10))
nx.draw(G,pos,node_size=200,edge_color=H_colors,font_size=10,with_labels=1,node_color="g")
plt.axis('on')
print("total edges",len(G.edges()))

"""# **Minimized final code**"""

import networkx as nx
import matplotlib.pyplot as plt
import random
import operator
import math
def function(D):
  print(D)
  SD=sorted(D.items(),key=operator.itemgetter(1),reverse=True)    #arranging degree values in descending order
  my_dict=dict(SD)                             #converting SD into dictionary
  L1=list(my_dict.keys())                      #storing the keys(nodes) of dictionary(my_dict) in a list (L1)
  print("values of Nodes in descending order : ",end="")
  print(my_dict)
  N_list=[]
  for u1 in range(0,len(L1)):
    for v1 in range(u1+1,len(L1)):
      m1=(L1[u1],L1[v1])
      N_list.append(m1)
  print("no.of node pairs which are their:",len(N_list))
  NUM=int(input("enter number of node pairs for evaluation:"))
  Hnode_list=[]
  for u2 in N_list[0:NUM]:
    Hnode_list.append(u2)
  print(Hnode_list)
  num=int(input("enter number of node pairs you want:"))
  for i5 in G.edges():
      G[i5[0]][i5[1]]['color'] = 'c'
                                          #analysis of average_shortest_path_length

  L_edge=[]         #it contain average_shortest_path_length values which are usefull in comparision
  print("####results of convensional graph####")
  print("average_shortest_path_length: ",nx.average_shortest_path_length(G))
  L_edge.append(nx.average_shortest_path_length(G))
  print("average_clustering: ",nx.average_clustering(G))
  print("####results after applying methode####")
  F_edge=[]         # it will contains all the node pairs which are participating in forming long range links for analysis
  no_of_LRlinks=[]
  for n5 in Hnode_list:
    if G.has_edge(*n5) is False:
      F_edge.append(n5)        #@#
      G.add_edge(*n5)
      print("*n5",*n5)
      L_edge.append(nx.average_shortest_path_length(G))
      print("L_edge",L_edge)
      if math.floor(L_edge[0]*10)/10==math.floor(nx.average_shortest_path_length(G)*10)/10:      # round(L_edge[0],10)!=round(nx.average_shortest_path_length(G),10) and
        G.remove_edge(*n5)
        pass
      else:
        G[n5[0]][n5[1]]['color'] = 'r'
        no_of_LRlinks.append(n5)
        print(n5,":average_shortest_path_length: ",nx.average_shortest_path_length(G))
        print("\taverage_clustering: ",nx.average_clustering(G))
      L_edge.pop(0)
    if len(no_of_LRlinks)==num:
      break
  print("node pairs that have particepated in forming long range links",F_edge,"=",len(F_edge))
  print("final node pairs which has new edges:",len(no_of_LRlinks))
  H_colors = [ G[m1[0]][m1[1]]['color'] for m1 in G.edges() ]
  plt.figure(figsize=(10,10))
  nx.draw(G,pos,node_size=200,edge_color=H_colors,font_size=10,with_labels=1,node_color="g")
  plt.axis('on')
  print("total edges",len(G.edges()))
  G.remove_edges_from(no_of_LRlinks)
  plt.figure(figsize=(10,10))
  nx.draw(G,pos,node_size=200,font_size=10,with_labels=1,node_color="g")
  plt.axis('on')
  print("total edges",len(G.edges()))
  ################################################################################################################
G=nx.random_geometric_graph(350,.6)
pos = nx.get_node_attributes(G,'pos')
print("coordinates before development",pos)
                                               #improving coordinates
for n in pos:
  x,y=pos[n]
  dx=x+random.randint(1,4999)
  dy=y+random.randint(1,4999)
  a=[dx,dy]
  pos.update({n:a})
print("coordinates after development",pos)
Xlist1=[]
Ylist1=[]
for n2 in pos:
  x1,y1=pos[n2]
  Xlist1.append(x1)
  Ylist1.append(y1)
dist_value1=[]
for e1 in range(0,len(Xlist1)):
  for f1 in range(e1+1,len(Xlist1)):
    distance1=math.sqrt(math.pow((Xlist1[e1]-Xlist1[f1]),2)+math.pow((Ylist1[e1]-Ylist1[f1]),2))        #In numpy distance2=np.sqrt(np.power((Xlist2[e2]-Xlist2[f2]),2)+np.power((Ylist2[e2]-Ylist2[f2]),2))
    dist_value1.append(distance1)
print("dist_value",len(dist_value1))
print("dist_value",dist_value1)
node_list1=[]                                     #storing node pairs such that 1st node and 2nd node in a list are taken in tuple
for u1 in pos:
  for v1 in range(u1+1,len(pos)):
    m1=(u1,v1)
    node_list1.append(m1)
print("node_list",len(node_list1))
print("node_list",node_list1)
dist_dict1={}                                         #storing the node pairs as keys and distances as values
for z1 in range(0,len(node_list1)):
  dist_dict1.update({node_list1[z1]:dist_value1[z1]})
print("dist_dict",len(dist_dict1))
nx.draw(G,pos,node_size=200,font_size=10,with_labels=1,node_color="g")
for i1 in G.edges():                                     #adding color
    G[i1[0]][i1[1]]['color'] = 'y'
for n4 in dist_dict1:                                     #adding shortest edges between nodes
  value1=dist_dict1.get(n4)
  if value1>500 and G.has_edge(*n4) is True:            #unpacks
    G.remove_edge(*n4)
  if value1<500 and G.has_edge(*n4) is False:
    G.add_edge(*n4)
    G[n4[0]][n4[1]]['color'] = 'r'
colors1 = [ G[i5[0]][i5[1]]['color'] for i5 in G.edges() ]
plt.figure(figsize=(10,10))
nx.draw(G,pos,node_size=200,edge_color=colors1,font_size=10,with_labels=1,node_color="g")
print("**************************nx.degree*******************************************")
function(dict(nx.degree(G)))
print("***********************nx.closeness_centrality********************************")
function(nx.closeness_centrality(G))
print("***********************nx.betweenness_centrality******************************")
function(nx.betweenness_centrality(G))

import networkx as nx
g=nx.gnp_random_graph(45,.3)
nx.draw(g,with_labels=1)
#g.size( )
print(nx.shortest_path(g,8,44))
print(nx.single_source_shortest_path(g,1,1))
print("average_shortest_path_length: ",nx.average_shortest_path_length(g))#####################################################################
print("average_clustering: ",nx.average_clustering(g))
g.size( )
print(g.nodes)
g.remove_node(43)
g.add_node(0.1234)
g.nodes()

import networkx as nx
import matplotlib.pyplot as plt
G = nx.watts_strogatz_graph(n=30 ,k=6,p=0.3)
#G = nx.DiGraph(G)
pos = nx.circular_layout(G)        #pos=nx.spring_layout(G) or nx.kamada_kawai_layout(G) or nx.circular_layout(G) or nx.spectral_layout(G) or nx.shell_layout(G) or nx.fruchterman_reingold_layout(G)
print(pos)
plt.figure(figsize=(50,50))
print("average_shortest_path_length: ",nx.average_shortest_path_length(G))#####################################################################
print("average_clustering: ",nx.average_clustering(G))
nx.draw(G,pos,node_size=500,font_size=10,with_labels=1,node_color="g")



print(G.edges)
for i in G.edges:
  if i[0]==i[1]-1:
    G.remove_edge(*i)
print(G.edges)
plt.figure(figsize=(50,50))
print("average_shortest_path_length: ",nx.average_shortest_path_length(G))#####################################################################
print("average_clustering: ",nx.average_clustering(G))
nx.draw(G,pos,node_size=500,font_size=10,with_labels=1,node_color="g")
G.edges()

import pandas as pd
nodes=pd.read_csv("train_X.csv")
print(nodes)

nodes_values={}
for n in pos:
  if n<30:
    values=nodes.iloc[0,n]
    nodes_values.update({n:values})
  if n<30:
    dx=1
    dy=n
  if 30<=n<50:
    dx=2
    dy=n-30
  if n>=30:
    dx=3
    dy=n-50
  a=[dx,dy]
  pos.update({n:a})
print(nodes_values)
print(pos)

plt.figure(figsize=(50,50))
nx.draw(G,pos,node_size=500,font_size=10,with_labels=1,node_color="g")

import random
a=random.randint(0,1)
print(a)

G.edges()

nodes

nodes.iloc[0,783]

import pandas as pd
df={12:[1,2,3],15:[2,3,4],25:[5,2,3]}
newdf=pd.DataFrame(df)#index=[0])
newdf

newdf.iloc[:,-1]

"""# observation by changing p value"""

import networkx as nx
import matplotlib.pyplot as plt
n=0
n1=[0]
for i1 in range(0,100):
  n=n+0.01
  n1.append(round(n,2))
for i in range(0,101):
    G = nx.watts_strogatz_graph(n=500,k=4,p=n1[i])########################################################################
    pos = nx.fruchterman_reingold_layout(G)  #nx.circular_layout(G)
    print("for probablity: ",n1[i])
    print("average_shortest_path_length: ",nx.average_shortest_path_length(G))#####################################################################
    print("average_clustering: ",nx.average_clustering(G))
plt.figure(figsize=(100,100))
    #plt.subplot(5,2,i)
nx.draw(G,pos,node_size=10000,font_size=50,with_labels=1,node_color="b",alpha=1,width=10)

"""###Removal of consecutive numbered edges

"""

import networkx as nx
G=nx.complete_graph(10)
#nx.draw_circular(G,with_labels=True)
print(G.edges)
for i in G.edges:
  if i[0]==i[1]-1:
    G.remove_edge(*i)
print(G.edges)
nx.draw_circular(G,with_labels=True)

"""# observations by changing k value"""

import networkx as nx
import matplotlib.pyplot as plt
#for i in range(4,10):
G = nx.watts_strogatz_graph(n=30,k=3,p=0.5)########################################################################
pos = nx.fruchterman_reingold_layout(G)  #nx.circular_layout(G)
#print("k value: ",k)
print("average_shortest_path_length: ",nx.average_shortest_path_length(G))#####################################################################
print("average_clustering: ",nx.average_clustering(G))
plt.figure(figsize=(100,100))
nx.draw(G,pos,node_size=10000,font_size=50,with_labels=1,node_color="b",alpha=1,width=10)

"""Checking that APL is changing with weights are not"""

import networkx as nx
g=nx.Graph()
g.add_node(1,pos=(0,6))
g.add_node(2,pos=(5,0))
g.add_node(3,pos=(9,4))
g.add_node(4,pos=(8,10))
g.add_node(5,pos=(15,0))
g.add_node(6,pos=(16,6))
g.add_node(7,pos=(13,11))
g.add_node(8,pos=(7,15))
g.add_edge(1,2,weight=1)
g.add_edge(2,4,weight=2)
g.add_edge(3,4,weight=3)
g.add_edge(5,6,weight=4)
g.add_edge(6,4,weight=5)
g.add_edge(4,8,weight=6)
g.add_edge(3,6,weight=7)
g.add_edge(1,4,weight=2)
g.add_edge(4,7,weight=3)
g.add_edge(4,5,weight=4)
g.add_edge(7,8,weight=5)
g.add_edge(2,5,weight=1)
pos=nx.get_node_attributes(g,'pos')
print(pos)
labels=nx.get_edge_attributes(g,'weight')
print(labels)
nx.draw_networkx_edge_labels(g,pos,edge_labels=labels)
nx.draw(g,pos,with_labels=1)
print("average_shortest_path_length: ",nx.average_shortest_path_length(g))
print('shortest_path=',nx.dijkstra_path(g,1,6))

import networkx as nx
g=nx.Graph()
g.add_node(1,pos=(0,6))
g.add_node(2,pos=(5,0))
g.add_node(3,pos=(9,4))
g.add_node(4,pos=(8,10))
g.add_node(5,pos=(15,0))
g.add_node(6,pos=(16,6))
g.add_node(7,pos=(13,11))
g.add_node(8,pos=(7,15))
g.add_edge(1,2)
g.add_edge(2,4)
g.add_edge(3,4)
g.add_edge(5,6)
g.add_edge(6,4)
g.add_edge(4,8)
g.add_edge(3,6)
g.add_edge(1,4)
g.add_edge(4,7)
g.add_edge(4,5)
g.add_edge(7,8)
g.add_edge(2,5)
pos=nx.get_node_attributes(g,'pos')
print(pos)
#nx.draw_networkx_edge_labels(g,pos,edge_labels=labels)
nx.draw(g,pos,with_labels=1)
print('shortest_path=',nx.dijkstra_path(g,1,6))
print("average_shortest_path_length: ",nx.average_shortest_path_length(g))



#distance included with 1000,1000 as center
p =nx.degree(D)
dict_deg = dict(p)
sorted_dic= sorted(dict_deg.items(), key=operator.itemgetter(1),        reverse=True)#[:100]
print(sorted_dic)
links=[]
apl=[]
acc=[]
Y=[0]
count=0
#for i4 in H.edges():                                     #adding color
#    H[i4[0]][i4[1]]['color'] = 'y'
#print("####results of convensional graph####")
#print(count,"average_shortest_path_length: ",nx.average_shortest_path_length(D))
apl.append(nx.average_shortest_path_length(D))
#print("average_clustering: ",nx.average_clustering(D))
acc.append(nx.average_clustering(D))
#print("####results after applying methode####")
for edge in D.edges():
  D.edges[edge]['width']=1
for i in range(0,300,2): #connecting nodes while iterating in the FOR loop
  d = math.sqrt(((coords[sorted_dic[i][0]][0]-coords[sorted_dic[i+1][0]][0])**2)+((coords[sorted_dic[i][0]][1]-coords[sorted_dic[i+1][0]][1])**2))
  if 1000<d<1500 and D.has_edge(sorted_dic[i][0],sorted_dic[i+1][0]) is False:
    D.add_edge(sorted_dic[i][0],sorted_dic[i+1][0])
    D.edges[sorted_dic[i][0],sorted_dic[i+1][0]]['width']=3
    D[sorted_dic[i][0]][sorted_dic[i+1][0]]['color'] = 'r'
    links.append([sorted_dic[i][0],sorted_dic[i+1][0]])
    count+=1
  #D[l[0]][l[1]]['color'] = 'g'
 # print((sorted_dic[i][0],sorted_dic[i+1][0]),count,":average_shortest_path_length: ",nx.average_shortest_path_length(H))
    apl.append(nx.average_shortest_path_length(D))
 # print("\taverage_clustering: ",nx.average_clustering(H))
    acc.append(nx.average_clustering(D))
    Y.append(count)
  if count==18:
    break
D_colors = [D[m1[0]][m1[1]]['color'] for m1 in D.edges()]
  #print(count)
print(Y)
print(links)
print(apl)
print(acc)
print(len(apl))
print(len(nx.edges(D)))
fig,ax = plt.subplots(figsize=(50,35))
nx.draw(D, pos, with_labels = True, edge_color=D_colors,node_size=500,node_color='g', width=[D.edges[edge]['width'] for edge in D.edges()],ax=ax,arrows=True)